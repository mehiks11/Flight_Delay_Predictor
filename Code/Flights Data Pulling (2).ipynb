{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fixed-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-miracle",
   "metadata": {},
   "source": [
    "# Flight Delay Classification Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-kennedy",
   "metadata": {},
   "source": [
    "This notebook outlines the code pull in more of the data that will later be used to create a classification model for flights being delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-cigarette",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-columbia",
   "metadata": {},
   "source": [
    "The main dataset was pulled from [kaggle](https://www.kaggle.com/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018/code \"2008-2019 Domestic Flight Data\"). \n",
    "\n",
    "The data from this source was initialized in the prior notebook [Flight Delays Initial Data Pulling (1)]()\n",
    "\n",
    "Additional data will need to be merged to our main dataframe, including:\n",
    "* Weather conditions (also pulled from [kaggle](https://www.kaggle.com/sobhanmoosavi/us-weather-events \"2016-2019 Adverse Airport Weather Conditions DataSet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-miniature",
   "metadata": {},
   "source": [
    "#### Pulling in data from first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "short-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/mehikapatel/Flights_Project/Data/FlightsDataAfterNB1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mechanical-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(subset=['DATE','AIRLINE','FLIGHT_NUM','ORIGIN','DEST'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-acting",
   "metadata": {},
   "source": [
    "*Drop the unnamed & AirportCode columns at the start & Make the DATE column a dt type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adjustable-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','AirportCode'],inplace=True)\n",
    "df.DATE=pd.to_datetime(df['DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-mystery",
   "metadata": {},
   "source": [
    "**This will create our target variable column. We decide to mark delays as those that are at least 20 minutes late in arrival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "local-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['ARR_DELAY']>=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-pakistan",
   "metadata": {},
   "source": [
    "**Now time to pull in historic weather data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "induced-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull weather data into dataframe\n",
    "weather_data=pd.read_csv('/Users/mehikapatel/Flights_Project/Data/WeatherEventsData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "direct-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unecessary columns from weather df\n",
    "weather_data.drop(columns=['EventId','County','ZipCode','State','EndTime(UTC)','TimeZone','LocationLat','LocationLng','AirportCode'],inplace=True)\n",
    "weather_data.rename({'City':'municipality1'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-switch",
   "metadata": {},
   "source": [
    "First we have to make the times compatible with our main df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "executed-belle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look at weather data\n",
    "weather_data['DATE']=pd.to_datetime(weather_data['StartTime(UTC)']).dt.date\n",
    "weather_data['DATE']=pd.to_datetime(weather_data['DATE'])\n",
    "weather_data.drop(columns=['StartTime(UTC)'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "great-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_data['StartHour']=weather_data['StartTime(UTC)'].dt.hour\n",
    "# weather_data['EndHour']=weather_data['EndTime(UTC)'].dt.hour\n",
    "weather_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "thick-northeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2502240 entries, 0 to 6273468\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   Type           object        \n",
      " 1   Severity       object        \n",
      " 2   municipality1  object        \n",
      " 3   DATE           datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 95.5+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ultimate-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge for municipality1\n",
    "df=df.merge(weather_data,how='left',on=['DATE','municipality1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decreased-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove some duplicates because of duplicates found. We originally had 12,477,222 data points. After \n",
    "# removing the original duplicates, we had 18426666. After removing our duplicates, we have ridden some of the data points.\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(subset=['DATE','AIRLINE','FLIGHT_NUM','ORIGIN','DEST'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "catholic-sigma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_type</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lon</th>\n",
       "      <th>municipality2</th>\n",
       "      <th>holiday_szn</th>\n",
       "      <th>DEP_HOUR</th>\n",
       "      <th>ARR_HOUR</th>\n",
       "      <th>target</th>\n",
       "      <th>origin_weather</th>\n",
       "      <th>origin_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1248</td>\n",
       "      <td>DTW</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1935</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>large</td>\n",
       "      <td>33.942501</td>\n",
       "      <td>-118.407997</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1251</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2125</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2321</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>medium</td>\n",
       "      <td>42.880798</td>\n",
       "      <td>-85.522797</td>\n",
       "      <td>Grand Rapids</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1255</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1656</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2229</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>large</td>\n",
       "      <td>33.636700</td>\n",
       "      <td>-84.428101</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>Fog</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1257</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BNA</td>\n",
       "      <td>1233</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1239</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>large</td>\n",
       "      <td>36.124500</td>\n",
       "      <td>-86.678200</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1257</td>\n",
       "      <td>BNA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1320</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>large</td>\n",
       "      <td>33.636700</td>\n",
       "      <td>-84.428101</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE         AIRLINE  FLIGHT_NUM ORIGIN DEST  CRS_DEP_TIME  DEP_TIME  \\\n",
       "0 2016-01-01  Delta Airlines        1248    DTW  LAX          1935    1935.0   \n",
       "2 2016-01-01  Delta Airlines        1251    ATL  GRR          2125    2130.0   \n",
       "3 2016-01-01  Delta Airlines        1255    SLC  ATL          1656    1700.0   \n",
       "5 2016-01-01  Delta Airlines        1257    ATL  BNA          1233    1356.0   \n",
       "6 2016-01-01  Delta Airlines        1257    BNA  ATL          1320    1446.0   \n",
       "\n",
       "   DEP_DELAY  CRS_ARR_TIME  ARR_DELAY  ...  dest_type   dest_lat    dest_lon  \\\n",
       "0        0.0          2144      -24.0  ...      large  33.942501 -118.407997   \n",
       "2        5.0          2321       -2.0  ...     medium  42.880798  -85.522797   \n",
       "3        4.0          2229      -16.0  ...      large  33.636700  -84.428101   \n",
       "5       83.0          1239       83.0  ...      large  36.124500  -86.678200   \n",
       "6       86.0          1530       74.0  ...      large  33.636700  -84.428101   \n",
       "\n",
       "   municipality2  holiday_szn DEP_HOUR  ARR_HOUR  target origin_weather  \\\n",
       "0    Los Angeles         True       19        21   False           Snow   \n",
       "2   Grand Rapids         True       21        23   False            NaN   \n",
       "3        Atlanta         True       16        22   False            Fog   \n",
       "5      Nashville         True       12        12    True            NaN   \n",
       "6        Atlanta         True       13        15    True            NaN   \n",
       "\n",
       "  origin_severity  \n",
       "0           Light  \n",
       "2             NaN  \n",
       "3          Severe  \n",
       "5             NaN  \n",
       "6             NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "victorian-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now remove hour data from weather_data  & rename municipality1 to municipality2\n",
    "weather_data.rename({'municipality1':'municipality2'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "charitable-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now rename in main df the type and severity columns\n",
    "df.rename({'Type':'origin_weather', 'Severity':'origin_severity'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "wrapped-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge for destination weather\n",
    "df=df.merge(weather_data,how='left',on=['DATE','municipality2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "demographic-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove some duplicates because of duplicates found. We originally had 12,477,222 data points. After \n",
    "# removing the duplicates on all columns, we had _____. After removing our duplicates, we have ridden some of the data points.\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(subset=['DATE','AIRLINE','FLIGHT_NUM','ORIGIN','DEST'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "comic-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_lon</th>\n",
       "      <th>municipality2</th>\n",
       "      <th>holiday_szn</th>\n",
       "      <th>DEP_HOUR</th>\n",
       "      <th>ARR_HOUR</th>\n",
       "      <th>target</th>\n",
       "      <th>origin_weather</th>\n",
       "      <th>origin_severity</th>\n",
       "      <th>dest_weather</th>\n",
       "      <th>dest_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1248</td>\n",
       "      <td>DTW</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1935</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-118.407997</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "      <td>Fog</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1251</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2125</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2321</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.522797</td>\n",
       "      <td>Grand Rapids</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snow</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1255</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1656</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2229</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.428101</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>Fog</td>\n",
       "      <td>Severe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1257</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BNA</td>\n",
       "      <td>1233</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1239</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.678200</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Delta Airlines</td>\n",
       "      <td>1257</td>\n",
       "      <td>BNA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1320</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.428101</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE         AIRLINE  FLIGHT_NUM ORIGIN DEST  CRS_DEP_TIME  DEP_TIME  \\\n",
       "0 2016-01-01  Delta Airlines        1248    DTW  LAX          1935    1935.0   \n",
       "1 2016-01-01  Delta Airlines        1251    ATL  GRR          2125    2130.0   \n",
       "2 2016-01-01  Delta Airlines        1255    SLC  ATL          1656    1700.0   \n",
       "3 2016-01-01  Delta Airlines        1257    ATL  BNA          1233    1356.0   \n",
       "4 2016-01-01  Delta Airlines        1257    BNA  ATL          1320    1446.0   \n",
       "\n",
       "   DEP_DELAY  CRS_ARR_TIME  ARR_DELAY  ...    dest_lon  municipality2  \\\n",
       "0        0.0          2144      -24.0  ... -118.407997    Los Angeles   \n",
       "1        5.0          2321       -2.0  ...  -85.522797   Grand Rapids   \n",
       "2        4.0          2229      -16.0  ...  -84.428101        Atlanta   \n",
       "3       83.0          1239       83.0  ...  -86.678200      Nashville   \n",
       "4       86.0          1530       74.0  ...  -84.428101        Atlanta   \n",
       "\n",
       "   holiday_szn  DEP_HOUR  ARR_HOUR target  origin_weather  origin_severity  \\\n",
       "0         True        19        21  False            Snow            Light   \n",
       "1         True        21        23  False             NaN              NaN   \n",
       "2         True        16        22  False             Fog           Severe   \n",
       "3         True        12        12   True             NaN              NaN   \n",
       "4         True        13        15   True             NaN              NaN   \n",
       "\n",
       "  dest_weather dest_severity  \n",
       "0          Fog      Moderate  \n",
       "1         Snow         Light  \n",
       "2          NaN           NaN  \n",
       "3          NaN           NaN  \n",
       "4          NaN           NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of duplicates\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "relevant-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename new columns\n",
    "df.rename({'Type':'dest_weather', 'Severity':'dest_severity'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv as final DF\n",
    "df.to_csv('/Users/mehikapatel/Flights_Project/FinalFlightsData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-intent",
   "metadata": {},
   "source": [
    "Make a subset for just 2018 flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulation-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only 2018\n",
    "year_2018=[2018]\n",
    "df['is_year']=df.YEAR.isin(year_2018)\n",
    "index_names = df[ df['is_year'] == False ].index\n",
    "data_2018 = df.drop(index_names)\n",
    "df.drop(columns=['is_year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "infectious-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018=data_2018.drop(columns=['DATE','FLIGHT_NUM','CRS_DEP_TIME','DEP_TIME','DEP_DELAY','CRS_ARR_TIME','ARR_DELAY',\n",
    "                                 'CANCELLED','origin_lat','origin_lon','dest_lat','dest_lon','YEAR','is_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thousand-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = data_2018.sample(10000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cubic-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 12265898 to 9587694\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   AIRLINE           10000 non-null  object \n",
      " 1   ORIGIN            10000 non-null  object \n",
      " 2   DEST              10000 non-null  object \n",
      " 3   CRS_ELAPSED_TIME  10000 non-null  float64\n",
      " 4   DISTANCE          10000 non-null  float64\n",
      " 5   MONTH             10000 non-null  int64  \n",
      " 6   DAYOFWEEK         10000 non-null  int64  \n",
      " 7   origin_type       9960 non-null   object \n",
      " 8   municipality_x    9960 non-null   object \n",
      " 9   dest_type         9938 non-null   object \n",
      " 10  municipality2     9938 non-null   object \n",
      " 11  holiday_szn       10000 non-null  bool   \n",
      " 12  DEP_HOUR          10000 non-null  int64  \n",
      " 13  ARR_HOUR          10000 non-null  int64  \n",
      " 14  target            10000 non-null  bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-finger",
   "metadata": {},
   "source": [
    "**There are about 12 million data points to work with, so we pull a random sample of 10,000 points for initial \n",
    "plotting purposes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-reducing",
   "metadata": {},
   "source": [
    "Plot Features from 2018 data for initial feature recognition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
